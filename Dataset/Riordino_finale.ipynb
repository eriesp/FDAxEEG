{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the features and find the ones statistically different in the two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the packages\n",
    "import numpy as np\n",
    "# import mne\n",
    "from tqdm import tqdm\n",
    "# from tqdm import tqdm\n",
    "import skfda\n",
    "import pandas as pd\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skfda.exploratory.visualization import Boxplot\n",
    "from skfda.inference.anova import oneway_anova\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import permutation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\OneDrive\\\\Documenti\\\\Uni_nuovo\\\\Necst\\\\NL2project\\\\FDAxEEG\\\\Dataset'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_path = os.path.abspath(os.getcwd())\n",
    "home_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the intergral of the absolute value of the first derivative\n",
    "$$ I = \\int \\|f'(t)\\| dt $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the integral of the first derivative\n",
    "def Integrale(canale, banda, home_path):\n",
    "    \n",
    "    # loading the data of ADHD\n",
    "    filename_adhd = home_path+\"\\ADHD_Matrici_medie\\zona\"+str(canale)+\"_p\"+str(banda)\n",
    "    mat = scipy.io.loadmat(filename_adhd)\n",
    "    PSD_ADHD=mat['avg']\n",
    "    df_Channel=pd.DataFrame(data=PSD_ADHD)\n",
    "    Channel=df_Channel.to_numpy(dtype=None, copy=False)\n",
    "    Channel = np.nan_to_num(Channel)\n",
    "    ADHD=skfda.FDataGrid(data_matrix=Channel)\n",
    "    ADHD.interpolation=skfda.representation.interpolation.SplineInterpolation(interpolation_order=3)\n",
    "\n",
    "    # loading the data of control\n",
    "    filename_control = home_path+\"\\Control_Matrici_medie\\zona\"+str(canale)+\"_p\"+str(banda)\n",
    "    mat = scipy.io.loadmat(filename_control)\n",
    "    PSD_control=mat['avg']\n",
    "    df_Channel=pd.DataFrame(data=PSD_control)\n",
    "    Channel=df_Channel.to_numpy(dtype=None, copy=False)\n",
    "    Channel = np.nan_to_num(Channel)\n",
    "    Control=skfda.FDataGrid(data_matrix=Channel)\n",
    "    Control.interpolation=skfda.representation.interpolation.SplineInterpolation(interpolation_order=3)\n",
    "\n",
    "    # compute the derivatives of the functions\n",
    "    ADHD_der=ADHD.derivative()\n",
    "    Control_der=Control.derivative()\n",
    "\n",
    "    # integral of the derivative of the adhd group\n",
    "    ADHD_der_abs = ADHD_der\n",
    "    ADHD_der_abs.data_matrix=np.abs(ADHD_der.data_matrix)\n",
    "\n",
    "    n_adhd = ADHD_der_abs.data_matrix.shape[0]\n",
    "\n",
    "    int_adhd = np.empty(n_adhd)\n",
    "    for i in range(n_adhd):\n",
    "        int_adhd[i]=scipy.integrate.simpson(np.transpose(ADHD_der_abs.data_matrix[i]), ADHD_der_abs.grid_points[0])\n",
    "        \n",
    "\n",
    "    # integral of the derivative of the control group\n",
    "    Control_der_abs = Control_der\n",
    "    Control_der_abs.data_matrix=np.abs(Control_der.data_matrix)\n",
    "\n",
    "    n_cont = Control_der_abs.data_matrix.shape[0]\n",
    "\n",
    "    int_cont = np.empty(n_cont)\n",
    "    for i in range(n_cont):\n",
    "        int_cont[i]=scipy.integrate.simpson(np.transpose(Control_der_abs.data_matrix[i]), Control_der_abs.grid_points[0])\n",
    "\n",
    "    return int_adhd, int_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistic for the permutation anova test\n",
    "def statistic(x, y):\n",
    "    comp=np.append(x,y)\n",
    "    num=len(x)*(np.mean(x)-np.mean(comp))**2+len(y)*(np.mean(y)-np.mean(comp))**2\n",
    "    den_x=0\n",
    "    den_y=0\n",
    "    \n",
    "    for i in np.arange(len(x)):    \n",
    "        den_x=den_x+(x[i]-np.mean(x))**2\n",
    "        \n",
    "    for j in np.arange(len(y)):\n",
    "        den_y=den_y+(y[j]-np.mean(y))**2\n",
    "        \n",
    "    return num/(den_x+den_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per calcolare integrali delle derivate e fare anova tra i due gruppi\n",
    "\n",
    "def AnovaIntDer(canale, banda, home_path):\n",
    "\n",
    "    int_adhd, int_cont = Integrale(canale, banda, home_path)\n",
    "\n",
    "\n",
    "    # ANOVA permutation test\n",
    "    res = permutation_test((int_adhd, int_cont), statistic,\n",
    "                       alternative='two-sided')\n",
    "\n",
    "    return res.pvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the p-values of the anova permutation test for each channel and for each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_val_int = np.empty((7,5))\n",
    "\n",
    "# for canale in range(1,8):\n",
    "#     for banda in range(1,6):\n",
    "#         p_val_int[(canale-1), (banda-1)] = AnovaIntDer(canale, banda, home_path)   \n",
    "\n",
    "# print(pd.DataFrame(p_val_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L^2$ norm study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norma(canale, banda, home_path, order=2):\n",
    "    \n",
    "    # loading the data of ADHD\n",
    "    filename_adhd = home_path+\"\\ADHD_Matrici_medie\\zona\"+str(canale)+\"_p\"+str(banda)\n",
    "    mat = scipy.io.loadmat(filename_adhd)\n",
    "    PSD_ADHD=mat['avg']\n",
    "    df_Channel=pd.DataFrame(data=PSD_ADHD)\n",
    "    Channel=df_Channel.to_numpy(dtype=None, copy=False)\n",
    "    Channel = np.nan_to_num(Channel)\n",
    "    ADHD=skfda.FDataGrid(data_matrix=Channel)\n",
    "    ADHD.interpolation=skfda.representation.interpolation.SplineInterpolation(interpolation_order=3)\n",
    "\n",
    "    # loading the data of control\n",
    "    filename_control = home_path+\"\\Control_Matrici_medie\\zona\"+str(canale)+\"_p\"+str(banda)\n",
    "    mat = scipy.io.loadmat(filename_control)\n",
    "    PSD_control=mat['avg']\n",
    "    df_Channel=pd.DataFrame(data=PSD_control)\n",
    "    Channel=df_Channel.to_numpy(dtype=None, copy=False)\n",
    "    Channel = np.nan_to_num(Channel)\n",
    "    Control=skfda.FDataGrid(data_matrix=Channel)\n",
    "    Control.interpolation=skfda.representation.interpolation.SplineInterpolation(interpolation_order=3)\n",
    "\n",
    "    # L2 norm of ADHD group\n",
    "    n_adhd = ADHD.data_matrix.shape[0]\n",
    "\n",
    "    norm_adhd = np.empty(n_adhd)\n",
    "    for i in range(n_adhd):\n",
    "        norm_adhd[i]=np.linalg.norm(ADHD.data_matrix[i], ord = order)\n",
    "\n",
    "    # L2 norm of control group\n",
    "    n_cont = Control.data_matrix.shape[0]\n",
    "\n",
    "    norm_cont = np.empty(n_cont)\n",
    "    for i in range(n_cont):\n",
    "        norm_cont[i]=np.linalg.norm(Control.data_matrix[i], ord = order)\n",
    "\n",
    "    # ANOVA\n",
    "\n",
    "    #aov = scipy.stats.f_oneway(norm_adhd,norm_cont, axis=0)\n",
    "    # print(\"ANOVA results: \\nF statistics: \\t\"+str(aov.statistic)+\"\\np_value: \\t\"+ str(aov.pvalue))\n",
    "\n",
    "    #res = permutation_test((norm_adhd, norm_cont), statistic, alternative='two-sided')\n",
    "    return norm_adhd, norm_cont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per calcolare norma L2 e fare anova tra i due gruppi\n",
    "\n",
    "def AnovaNormLp(canale, banda, home_path, order=2):\n",
    "    \n",
    "    norm_adhd, norm_cont = Norma(canale, banda, home_path, order=order)\n",
    "    \n",
    "    res = permutation_test((norm_adhd, norm_cont), statistic,\n",
    "                       alternative='two-sided')\n",
    "    \n",
    "    return res.pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_val_norm = np.empty((7,5))\n",
    "\n",
    "# for canale in range(1,8):\n",
    "#     for banda in range(1,6):\n",
    "#         p_val_norm[(canale-1), (banda-1)] = AnovaNormLp(canale, banda, home_path)\n",
    "\n",
    "# print(pd.DataFrame(p_val_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estremo massimo (picco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Picco(canale, banda, home_path):\n",
    "    \n",
    "    # loading the data of ADHD\n",
    "    filename_adhd = home_path+\"\\ADHD_Matrici_medie\\zona\"+str(canale)+\"_p\"+str(banda)\n",
    "    mat = scipy.io.loadmat(filename_adhd)\n",
    "    PSD_ADHD=mat['avg']\n",
    "    df_Channel=pd.DataFrame(data=PSD_ADHD)\n",
    "    Channel=df_Channel.to_numpy(dtype=None, copy=False)\n",
    "    Channel = np.nan_to_num(Channel)\n",
    "    ADHD=skfda.FDataGrid(data_matrix=Channel)\n",
    "    ADHD.interpolation=skfda.representation.interpolation.SplineInterpolation(interpolation_order=3)\n",
    "\n",
    "    # loading the data of control\n",
    "    filename_control = home_path+\"\\Control_Matrici_medie\\zona\"+str(canale)+\"_p\"+str(banda)\n",
    "    mat = scipy.io.loadmat(filename_control)\n",
    "    PSD_control=mat['avg']\n",
    "    df_Channel=pd.DataFrame(data=PSD_control)\n",
    "    Channel=df_Channel.to_numpy(dtype=None, copy=False)\n",
    "    Channel = np.nan_to_num(Channel)\n",
    "    Control=skfda.FDataGrid(data_matrix=Channel)\n",
    "    Control.interpolation=skfda.representation.interpolation.SplineInterpolation(interpolation_order=3)\n",
    "\n",
    "    Picco_ADHD=ADHD.data_matrix.max(1)\n",
    "\n",
    "    Picco_Control=Control.data_matrix.max(1)\n",
    "\n",
    "    return Picco_ADHD, Picco_Control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per calcolare picchi fare anova tra i due gruppi\n",
    "\n",
    "def AnovaPicco(canale, banda, home_path):\n",
    "    \n",
    "    Picco_ADHD, Picco_Control = Picco(canale, banda, home_path)\n",
    "    \n",
    "    res = permutation_test((Picco_ADHD, Picco_Control), statistic,\n",
    "                       alternative='two-sided')\n",
    "    return res.pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_val_picco = np.empty((7,5))\n",
    "\n",
    "# for canale in range(1,8):\n",
    "#     for banda in range(1,6):\n",
    "#         p_val_picco[(canale-1), (banda-1)] = AnovaPicco(canale, banda, home_path)\n",
    "\n",
    "# print(pd.DataFrame(p_val_picco))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Li abbiamo già noi quindi li importo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  6  7  8 19 24 29 30 31 32 33]\n",
      "Zona: 1\tBanda: 0\n",
      "Zona: 1\tBanda: 1\n",
      "Zona: 1\tBanda: 2\n",
      "Zona: 1\tBanda: 3\n",
      "Zona: 3\tBanda: 4\n",
      "Zona: 4\tBanda: 4\n",
      "Zona: 5\tBanda: 4\n",
      "Zona: 6\tBanda: 0\n",
      "Zona: 6\tBanda: 1\n",
      "Zona: 6\tBanda: 2\n",
      "Zona: 6\tBanda: 3\n"
     ]
    }
   ],
   "source": [
    "# per risalire dall'elemento del vettore al canale e banda basta sapere che se ci si trova in\n",
    "# posizione i \n",
    "# i = 5*zona + banda\n",
    "# zona = i mod 5 \n",
    "# banda = i - i mod 5 * 5\n",
    "\n",
    "p_val_int = np.array([0.5286,  0.4052,  0.3312,  0.1022,  0.2952,\n",
    "                      0.0454,  0.0394,  0.0002,  0.0002,  0.2352,\n",
    "                      0.4528,  0.5666,  0.1252,  0.1166,  0.7752,\n",
    "                      0.6408,  0.5594,  0.6018,  0.0728,  0.0014,\n",
    "                      0.3272,  0.2708,  0.1088,  0.2588,  0.0224,\n",
    "                      0.1526,  0.9322,  0.3024,  0.2476,  0.0456,\n",
    "                      0.0002,  0.0002,  0.0032,  0.0304,  0.4020])\n",
    "\n",
    "\n",
    "indxs = np.where(p_val_int <= 0.05)[0]\n",
    "print(indxs)\n",
    "\n",
    "matrice_int_adhd = np.empty((555,indxs.size))\n",
    "matrice_int_cont = np.empty((427,indxs.size))\n",
    "\n",
    "# salvo le features di mio interesse\n",
    "# della zona e banda di mio interesse devo avere vettore integrali di adhd e vettore integrali di control\n",
    "for i,indx in enumerate(indxs):\n",
    "    zona = indx//5\n",
    "    banda = indx - indx//5*5\n",
    "    int_adhd, int_cont = Integrale(canale=zona+1,  banda=banda+1, home_path=home_path)\n",
    "    matrice_int_adhd[:,i] = int_adhd\n",
    "    matrice_int_cont[:,i] = int_cont\n",
    "    \n",
    "mat_int_adhd = pd.DataFrame(matrice_int_adhd)\n",
    "mat_int_cont = pd.DataFrame(matrice_int_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_int_adhd.to_csv(home_path+'\\Feat_int_adhd.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_int_cont.to_csv(home_path+'\\Feat_int_cont.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  5  6  7  8 19 20 24 30 31 32 33]\n",
      "Zona: 0\tBanda: 3\n",
      "Zona: 1\tBanda: 0\n",
      "Zona: 1\tBanda: 1\n",
      "Zona: 1\tBanda: 2\n",
      "Zona: 1\tBanda: 3\n",
      "Zona: 3\tBanda: 4\n",
      "Zona: 4\tBanda: 0\n",
      "Zona: 4\tBanda: 4\n",
      "Zona: 6\tBanda: 0\n",
      "Zona: 6\tBanda: 1\n",
      "Zona: 6\tBanda: 2\n",
      "Zona: 6\tBanda: 3\n"
     ]
    }
   ],
   "source": [
    "p_val_norm = np.array([0.6820,  0.6504,  0.3608,  0.0118,  0.3410,\n",
    "                    0.0002,  0.0012,  0.0002,  0.0002,  0.1232,\n",
    "                    0.2532,  0.1022,  0.2542,  0.2148,  0.4512,\n",
    "                    0.8926,  0.8962,  0.1468,  0.0526,  0.0016,\n",
    "                    0.0204,  0.2140,  0.1850,  0.2968,  0.0410,\n",
    "                    0.6058,  0.0620,  0.4740,  0.3442,  0.0656,\n",
    "                    0.0002,  0.0002,  0.0062,  0.0164,  0.9768])\n",
    "\n",
    "\n",
    "indxs = np.where(p_val_norm <= 0.05)[0]\n",
    "print(indxs)\n",
    "\n",
    "matrice_norm_adhd = np.empty((555,indxs.size))\n",
    "matrice_norm_cont = np.empty((427,indxs.size))\n",
    "\n",
    "# salvo le features di mio interesse\n",
    "# della zona e banda di mio interesse devo avere vettore integrali di adhd e vettore integrali di control\n",
    "for i,indx in enumerate(indxs):\n",
    "    zona = indx//5\n",
    "    banda = indx - indx//5*5\n",
    "    norm_adhd, norm_cont = Norma(canale=zona+1,  banda=banda+1, home_path=home_path)\n",
    "    matrice_norm_adhd[:,i] = norm_adhd\n",
    "    matrice_norm_cont[:,i] = norm_cont\n",
    "\n",
    "pd.DataFrame(matrice_norm_adhd).to_csv(home_path+'\\Feat_norm_adhd.csv', index = False, sep = ',')\n",
    "pd.DataFrame(matrice_norm_cont).to_csv(home_path+'\\Feat_norm_cont.csv', index = False, sep = ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  7  8 19 24 29 30 31 32 33]\n",
      "Zona: 0\tBanda: 3\n",
      "Zona: 1\tBanda: 2\n",
      "Zona: 1\tBanda: 3\n",
      "Zona: 3\tBanda: 4\n",
      "Zona: 4\tBanda: 4\n",
      "Zona: 5\tBanda: 4\n",
      "Zona: 6\tBanda: 0\n",
      "Zona: 6\tBanda: 1\n",
      "Zona: 6\tBanda: 2\n",
      "Zona: 6\tBanda: 3\n"
     ]
    }
   ],
   "source": [
    "p_val_picco = np.array([0.7554,  0.2928,  0.1538,  0.0290,  0.2234,\n",
    "                    0.0880,  0.1310,  0.0004,  0.0002,  0.9514,\n",
    "                    0.2384,  0.4092,  0.7544,  0.0978,  0.7872,\n",
    "                    0.9306,  0.5938,  0.4330,  0.0506,  0.0004,\n",
    "                    0.3982,  0.7732,  0.2830,  0.1536,  0.0210,\n",
    "                    0.2098,  0.9840,  0.9844,  0.7440,  0.0310,\n",
    "                    0.0002,  0.0002,  0.0150,  0.0030,  0.1934])\n",
    "\n",
    "\n",
    "indxs = np.where(p_val_picco <= 0.05)[0]\n",
    "print(indxs)\n",
    "\n",
    "matrice_picco_adhd = np.empty((555,indxs.size))\n",
    "matrice_picco_cont = np.empty((427,indxs.size))\n",
    "\n",
    "# salvo le features di mio interesse\n",
    "# della zona e banda di mio interesse devo avere vettore integrali di adhd e vettore integrali di control\n",
    "for i,indx in enumerate(indxs):\n",
    "    zona = indx//5\n",
    "    banda = indx - indx//5*5\n",
    "    picco_adhd, picco_cont = Picco(canale=zona+1,  banda=banda+1, home_path=home_path)\n",
    "    matrice_picco_adhd[:,i] = np.reshape(picco_adhd, (555,))\n",
    "    matrice_picco_cont[:,i] = np.reshape(picco_cont, (427,))\n",
    "    \n",
    "    print('Zona: '+str(zona)+'\\tBanda: '+str(banda))\n",
    "\n",
    "pd.DataFrame(matrice_picco_adhd).to_csv(home_path+'\\Feat_picco_adhd.csv', index = False, sep = ',')\n",
    "pd.DataFrame(matrice_picco_cont).to_csv(home_path+'\\Feat_picco_cont.csv', index = False, sep = ',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "532c0ad4d7e0572bfd0188361c6d99f4735bba3972b8cb24208c1b963abc683b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
